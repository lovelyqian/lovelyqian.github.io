---
layout: archive
title: "中文"
permalink: /chinese/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}



教育背景
------
* <strong>苏黎世联邦理工学院</strong> (2023-)
  * 博士后
* <strong>复旦大学</strong> (2018-2023)
  * 硕博连读生
  * GPA: 3.7/4.0 (<strong>专业第一</strong>)
  * 专业: 计算机应用技术
  * 研究方向：计算机视觉，尤其是小样本视频动作识别，跨域小样本学习
* <strong>浙江工业大学</strong> (2014-2018) (荣誉毕业生)
  * 工学学士
  * GPA: 4.2/5.0 (<strong>专业第一</strong>)
  * 专业: 计算机科学与技术及自动化双专业一体化



学术任职
------
* 期刊审稿人：TPAMI, IJCV, TIP, TMLR, TNNLS, Information Fusion, TMM, TCSVT, Neurocomputing, TOMM, MVAP
* 会议审稿人：CVPR(2023/24), ECCV-2024, ICCV-2023, ACM MM(2023/24), AAAI-2022, WACV-2024
<!-- * AAAI 2022 程序委员会成员（PC）-->




学术活动
------
* 第一届跨域小样本物体检测CD-FSOD挑战赛组织者 （2025）
* 2021/2022 国际青少年人工智能交流展示会（IAIF）<strong>专家评委</strong>
* 2021 世界人工智能大会（WAIC）<strong>秘书处成员</strong>
* 中国计算机学会（CCF）校园宣传大使 (2019-2022)



奖项荣誉
------
* 第二届EgoVis（第一人称视角）Ego-Exo4D Correspondence挑战赛第二名 （2025）
* 上海市优秀毕业生 (2023) 
* <strong>复旦大学优秀学生标兵</strong> (2021) (全校仅<strong>10</strong>名，<strong>Top 0.03%</strong>)
* 研究生<strong>国家奖学金</strong> (2019) (<strong>Top 2%</strong>)
* <strong>国家奖学金</strong> (2016, 2017) (<strong>Top 0.4%</strong>)
* <strong>CCF全国优秀大学生</strong> (2017) （全校仅<strong>2</strong>名）
* <strong>浙江省万名好党员</strong> （2018）（全校仅<strong>3</strong>名学生）
* 浙江省普通高等学校优秀毕业生 (2018) 
* 复旦英特尔冠名奖学金 （2022）
* 复旦华为冠名奖学金 （2021）
* 复旦大学优秀团干部 （2019）





科研工作
------
<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/ObjectRelator.png" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">ObjectRelator: Enabling Cross-View Object Relation Understanding in Ego-Centric and Exo-Centric Perspectives</span><br>
             <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Runze Wang, Bin Ren, Guolei Sun, Biao Gong, Yanwei Fu, Danda Pani Paudel, Xuanjing Huang, Luc Van Gool</span></span><br>
             <span style="font-weight:normal;font-size:16px"> International Conference on Computer Vision (<strong>ICCV</strong>), 2025</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2411.19083">论文</a>][<a href="https://github.com/lovelyqian/ObjectRelator">代码</a>][<a href="">Youtube视频 (Coming Soon) </a>][<a href="">Bilibili视频 (Coming Soon) </a>][<a href="">项目主页(Coming Soon) </a>]</span>
    </th>
  </tr> 
</table>


<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/RAG6DPose.png" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">RAG-6DPose: Retrieval-Augmented 6D Pose Estimation via Leveraging CAD as Knowledge Base</span>
            <br><span style="font-size:16px; font-weight:normal">
            Kuanning Wang, <strong>Yuqian Fu ‡</strong>, Tianyu Wang, Yanwei Fu, Longfei Liang, Yu-Gang Jiang, Xiangyang Xue
            </span><br>
            <span style="font-weight:normal;font-size:16px"> International Conference on Intelligent Robots and Systems (<strong>IROS</strong>), 2025</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2506.18856">论文</a>][<a href="">代码 (Coming Soon)</a>][<a href="https://sressers.github.io/RAG-6DPose/">项目主页</a>]</span>
    </th>
  </tr> 
</table>

<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/CAFuser.jpg" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">CAFuser: Condition-Aware Multimodal Fusion for Robust Semantic Perception of Driving Scenes</span><br>
            Tim Brödermann ‡, Christos Sakaridis,  <span style="font-size:16px">Yuqian Fu ‡<span style="font-weight:normal">, Luc Van Gool</span></span><br>
             <span style="font-weight:normal;font-size:16px">IEEE Robotics and Automation Letters (<strong>RA-L</strong>), 2025</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2410.10791">论文</a>][<a href="https://github.com/timbroed/CAFuser">代码</a>][<a href="">Youtube视频 (coming soon) </a>][<a href="">Bilibili视频 (coming soon) </a>][<a href="">项目主页 (coming soon)</a>]</span>
    </th>
  </tr> 
</table>

<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/LAE.jpg" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">Locate Anything on Earth: Advancing Open-Vocabulary Object Detection for Remote Sensing Community</span><br>
            Jiancheng Pan, Yanxing Liu, <span style="font-size:16px">Yuqian Fu ‡<span style="font-weight:normal">, Muyuan Ma, Jiahao Li, Danda Pani Paudel, Luc Van Gool, Xiaomeng Huang ‡</span></span><br>
             <span style="font-weight:normal;font-size:16px">The AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2025</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2408.09110">论文</a>][<a href="https://github.com/jaychempan/LAE-DINO">代码</a>][<a href="">Youtube视频 (coming soon) </a>][<a href="">Bilibili视频 (coming soon) </a>][<a href="https://jianchengpan.space/LAE-website/index.html">项目主页</a>]</span>
    </th>
  </tr> 
</table>

<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/cdfsod-benchmark.jpg" width="350"/>
    </th>
      <th style="text-align:left" width="70%">
            <span style="font-size:18px">Cross-Domain Few-Shot Object Detection via Enhanced Open-Set Object Detector</span><br>
            <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Yu Wang, Yixuan Pan, Lian Huai, Xingyu Qiu, Zeyu Shangguan, Tong Liu, Yanwei Fu, Luc Van Gool, Xingqun Jiang</span></span><br>
             <span style="font-weight:normal;font-size:16px">The European Conference on Computer Vision (<strong>ECCV</strong>), 2024</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2402.03094">论文</a>][<a href="https://github.com/lovelyqian/CDFSOD-benchmark">代码</a>][<a href="https://www.youtube.com/watch?v=t5vREYQIup8">Youtube视频</a>][<a href="https://www.bilibili.com/video/BV17v4UetEdF/?vd_source=668a0bb77d7d7b855bde68ecea1232e7#reply113142138936707">Bilibili视频</a>][<a href="http://yuqianfu.com/CDFSOD-benchmark">项目主页</a>]</span>
    </th>
  </tr> 
</table>

<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/mind3d.jpg" width="350"/>
    </th>
      <th style="text-align:left" width="70%">
            <span style="font-size:18px">MinD-3D: Reconstruct High-quality 3D objects
in Human Brain</span><br>
            Jianxiong Gao, <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Yun Wang, Xuelin Qian, Jianfeng Feng, Yanwei Fu</span></span><br>
             <span style="font-weight:normal;font-size:16px">The European Conference on Computer Vision (<strong>ECCV</strong>), 2024</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/abs/2312.07485">论文</a>][<a href="https://huggingface.co/datasets/Fudan-fMRI/fMRI-Shape">代码</a>][<a href="https://jianxgao.github.io/MinD-3D">项目主页</a>]</span>
    </th>
  </tr> 
</table>


<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/framework-OVRE.jpg" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">Open-Vocabulary Video Relation Extraction</span><br>
            <span style="font-size:16px"><span style="font-weight:normal">Wentao Tian, Zheng Wang, </span> Yuqian Fu<span style="font-weight:normal">, Jingjing Chen, Lechao Cheng</span></span><br>
            <span style="font-weight:normal;font-size:16px">AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2024.</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/abs/2312.15670">论文</a>]</span>
    </th>
  </tr> 
</table>

<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/framework-SACT.jpg" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">On the Importance of Spatial Relations for Few-shot Action Recognition</span><br>
            <span style="font-size:16px"><span style="font-weight:normal">Yilun Zhang</span>, Yuqian Fu<span style="font-weight:normal">, Xingjun Ma, Lizhe Qi, Jingjing Chen, Yu-Gang Jiang</span></span><br>
            <span style="font-weight:normal;font-size:16px">ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2023.</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2308.07119.pdf">论文</a>]</span>
    </th>
  </tr> 
</table>

<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/framework-styleadv.jpg" width="350"/>
    </th>
     <th style="text-align:left" width="70%">
            <span style="font-size:18px">StyleAdv: Meta Style Adversarial Training for Cross-Domain Few-Shot Learning</span><br>
            <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Yu Xie, Yanwei Fu, Yu-Gang Jiang</span></span><br>
             <span style="font-weight:normal;font-size:16px">IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2302.09309.pdf">论文</a>][<a href="https://github.com/lovelyqian/StyleAdv-CDFSL">代码</a>][<a href="https://youtu.be/YB-S2YF22mc">Youtube视频</a>][<a href="https://www.bilibili.com/video/BV1th4y1s78H/?spm_id_from=333.999.0.0&vd_source=668a0bb77d7d7b855bde68ecea1232e7">B站视频</a>][<a href="http://yuqianfu.com/PJ-StyleAdv">项目主页</a>]</span>
    </th>
  </tr> 
</table>

<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/framework-GMetaFDMixup.jpg" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">Generalized Meta-FDMixup: Cross-Domain Few-Shot Learning Guided by Labeled Target Data</span><br>
            <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Yanwei Fu, Jingjing Chen, Yu-Gang Jiang</span></span><br>
            <span style="font-weight:normal;font-size:16px">IEEE Transactions on Image Processinig (<strong>TIP</strong>), 2022.</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9942934">论文</a>]</span>
    </th>
  </tr> 
</table>


<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/framework-MED2N.png" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">ME-D2N: Multi-Expert Domain Decompositional Network for Cross-Domain Few-Shot Learning</span><br>
            <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Yu Xie, Yanwei Fu, Jingjing Chen, Yu-Gang Jiang</span></span><br>
            <span style="font-weight:normal;font-size:16px">ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2022.</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2210.05280.pdf">论文</a>][<a href="https://github.com/lovelyqian/ME-D2N_for_CDFSL">代码</a>][<a href="https://www.youtube.com/watch?v=crCoaBLuFeA">Youtube视频</a>][<a href="https://www.bilibili.com/video/BV1GG4y1p7if/?vd_source=668a0bb77d7d7b855bde68ecea1232e7">B站视频</a>]</span>
    </th>
  </tr> 
</table>

<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/framework-TGDM.png" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">TGDM: Target Guided Dynamic Mixup for Cross-Domain Few-Shot Learning</span><br>
            <span style="font-size:16px"><span style="font-weight:normal">Linhai Zhuo</span>, Yuqian Fu<span style="font-weight:normal">, Jingjing Chen, Yixin Cao, Yu-Gang Jiang</span></span><br>
            <span style="font-weight:normal;font-size:16px">ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2022.</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2210.05392.pdf">论文</a>]</span>
    </th>
  </tr> 
</table>

<table style="width:100%">
  <tr>
    <th width="30%">
       <img src="../images/framework-waveSAN.png" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
  <span style="font-size:18px">Wave-SAN: Wavelet based Style Augmentation Network for Cross-Domain Few-Shot Learning</span><br>
            <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Yu Xie, Yanwei Fu, Jingjing Chen, Yu-Gang Jiang</span></span><br>
            <span style="font-weight:normal;font-size:16px">arXiv preprint, 2022.</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2203.07656.pdf">论文</a>]</span>
    </th>
  </tr> 
</table>


<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/framework-metaFDMixup.png" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">Meta-FDMixup: Cross-Domain Few-Shot Learning Guided by Labeled Target Data</span><br>
            <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Yanwei Fu, Yu-Gang Jiang</span></span><br>
            <span style="font-weight:normal;font-size:16px">ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2021.</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2107.11978.pdf">论文</a>][<a href="https://github.com/lovelyqian/Meta-FDMixup">代码</a>][<a href="https://www.youtube.com/watch?v=G8Mlde4FpsU">Youtube视频</a>][<a href="https://www.bilibili.com/video/BV1xT4y1f7B6?spm_id_from=333.999.0.0&vd_source=668a0bb77d7d7b855bde68ecea1232e7">B站视频</a>][<a href="http://yuqianfu.com/PJ-MetaFDMixup">项目主页</a>]</span>
    </th>
  </tr> 
</table>



<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/framework-ActionImitation.png" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">Can Action be Imitated? Learn to Reconstruct and Transfer Human Dynamics from Videos</span><br>
            <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Yanwei Fu, Yu-Gang Jiang</span></span><br>
            <span style="font-weight:normal;font-size:16px">International Conference on Multimedia Retrieval (<strong>ICMR</strong>). 2021. (<strong>Oral</strong>)</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2107.11756.pdf">论文</a>][<a href="https://www.bilibili.com/video/BV1VY41147xt?spm_id_from=333.999.0.0">B站视频</a>]</span>
    </th>
  </tr> 
</table>


<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/framework-AMeFu.png" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
             <span style="font-size:18px">Depth Guided Adaptive Meta-Fusion Network for Few-shot Video Recognition</span><br>
            <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Li Zhang, Junke Wang, Yanwei Fu, Yu-Gang Jiang</span></span><br>
            <span style="font-weight:normal;font-size:16px">ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2020. (<strong>Oral</strong>)</span><br>
            <span style="font-weight:normal;font-size:16px">[<a href="https://arxiv.org/pdf/2010.09982.pdf">论文</a>][<a href="https://github.com/lovelyqian/AMeFu-Net">代码</a>][<a href="https://www.youtube.com/watch?v=KqNYuZD5xdw">Youtube视频</a>][<a href="https://www.bilibili.com/video/BV1i44y1t78U?spm_id_from=333.999.0.0">B站视频</a>][<a href="http://yuqianfu.com/PJ-AMeFuNet">项目主页</a>]</span>
    </th>
  </tr> 
</table>


<table style="width:100%">
  <tr>
    <th width="30%">
      <img src="../images/framework-embodied.png" width="350"/>
    </th>
    <th style="text-align:left" width="70%">
            <span style="font-size:18px">Embodied One-Shot Video Recognition: Learning from Actions of a Virtual Embodied Agent</span><br>
            <span style="font-size:16px">Yuqian Fu<span style="font-weight:normal">, Chengrong Wang, Yanwei Fu, Yu-Xiong Wang, Cong Bai, Xiangyang Xue, Yu-Gang Jiang</span></span><br>
            <span style="font-weight:normal;font-size:16px">ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2019. (<strong>Oral</strong>)</span><br>
            <span style="font-weight:normal;font-size:16px"> [<a href="http://www.cs.cmu.edu/~yuxiongw/research/Embodied_One-Shot_Video_Recognition_Learning_from_Actions_of_a_Virtual_Embodied_Agent.pdf">论文</a>][<a href="https://github.com/lovelyqian/Embodied-One-Shot-Video-Recognition">代码</a>][<a href="http://yuqianfu.com/UnrealAction-Dataset">UnrealAction数据集</a>]</span>
    </th>
  </tr> 
</table>


学生工作
------
* 班级心理委员 （2021-2022）
* 学生团支部书记 (2018-2021)
* 学生党支部书记 （2017-2018）
* 新生助理班主任 （2015-2018）
* 体育部副部长 （2014-2016）


专业能力
------
* 编程语言：**Python**, **Pytorch**
* 专业工具：Latex, Vim, Matlab, Meshlab


更多信息
------
* 中文博客[在这里](https://www.jianshu.com/u/b3c66a77e742).


<!-- Publications
======
  <ul>{% for post in site.publications %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul>
  
Talks
======
  <ul>{% for post in site.talks %}
    {% include archive-single-talk-cv.html %}
  {% endfor %}</ul>
  
Teaching
======
  <ul>{% for post in site.teaching %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul> -->
  


